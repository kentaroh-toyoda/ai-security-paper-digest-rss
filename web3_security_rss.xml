<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Web3 Security Paper Digest</title><link>https://kentaroh-toyoda.github.io/ai-security-paper-digest-rss/web3_security_rss.xml</link><description>Curated papers on Web3, blockchain, and smart contract security from ArXiv and ACL</description><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><lastBuildDate>Thu, 05 Feb 2026 02:38:39 +0000</lastBuildDate><item><title>SCALM: Detecting Bad Practices in Smart Contracts Through LLMs</title><link>https://arxiv.org/abs/2502.04347</link><description>&lt;h3&gt;Summary&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Presents the first systematic study of bad practices in smart contracts, covering over 35 specific issues.&lt;/li&gt;&lt;li&gt;Proposes SCALM, an LLM-based framework that combines Step-Back Prompting and Retrieval-Augmented Generation (RAG) to detect and remediate bad practices.&lt;/li&gt;&lt;li&gt;Evaluates SCALM across multiple LLMs and datasets, showing it outperforms existing tools for detecting bad practices in smart contracts.&lt;/li&gt;&lt;li&gt;Focuses on code quality and bad practices that increase risk, complementing traditional vulnerability detection approaches.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Paper Type&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Research&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Additional Information&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Authors: ['Zongwei Li', 'Xiaoqi Li', 'Wenkai Li', 'Xin Wang']&lt;/li&gt;&lt;li&gt;Tags: ['smart-contracts', 'smart-contract-security', 'LLMs', 'vulnerability-detection', 'static-analysis']&lt;/li&gt;&lt;/ul&gt;</description><guid isPermaLink="false">https://arxiv.org/abs/2502.04347</guid><pubDate>Thu, 05 Feb 2026 00:00:00 +0000</pubDate></item></channel></rss>